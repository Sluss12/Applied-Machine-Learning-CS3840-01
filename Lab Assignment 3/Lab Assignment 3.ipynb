{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3e7773d",
   "metadata": {},
   "source": [
    "### CS 3840 Applied Machine Learning - Lab Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057fb92a",
   "metadata": {},
   "source": [
    "# <center>Random Forest and Neural Networks</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd0a0d2",
   "metadata": {},
   "source": [
    "### 1. Overview\n",
    "An ensemble of decision tree is called random forest. Despite its simplicity, this is one of the most powerful shallow learning algorithms available today. Neural networks are at very core of deep learning, which are versatile, powerful, and scalable, making them ideal to tackle large and highly complex machine learning tasks. The learning objective of this lab assignment is for students to understand random forest and neural networks, including how to train these models with the impacts of key parameters, how to evaluate their classification performances, and how to compare these results among different classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633487e0",
   "metadata": {},
   "source": [
    "#### Lecture notes and code demonstrations. \n",
    "Detailed coverage of these topics can be found in the following:\n",
    "<li>Lecture 2022-03-16-W-Ensemble Learning</li>\n",
    "<li>Lecture 2022-03-21-M-Ensemble Learning and Random Forest</li>\n",
    "<li>Code-Ensemble Learning and Random Forest</li>\n",
    "<li>Lecture 2022-03-23-W-Neural Networks</li>\n",
    "<li>Lecture 2022-03-28-M-Neural Networks-2</li>\n",
    "<li>Lecture 2022-03-30-W-Neural Networks-3</li>\n",
    "<li>Lecture 2022-04-04-M-Neural Networks-4</li>\n",
    "<li>Lecture 2022-04-06-W-Neural Networks-5</li>\n",
    "<li>Code-Neural Networks</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d253216",
   "metadata": {},
   "source": [
    "### 2. Submission\n",
    "You need to submit a detailed lab report with code, running results, and answers to the questions. If you submit <font color='red'>a jupyter notebook (“Firstname-Lastname-Lab3.ipynd”)</font>, please fill in this file directly and place the code, running results, and answers in order for each question. If you submit <font color='red'>a PDF report (“Firstname-Lastname-Lab3.pdf”) with code file (“Firstname-Lastname-Lab3.py”)</font>, please include the screenshots (code and running results) with answers for each question in the report.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7802ac85",
   "metadata": {},
   "source": [
    "### 3. Questions (50 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bffccc",
   "metadata": {},
   "source": [
    "For this lab assignment, you will be using the `MNIST dataset` to complete the following tasks and answer the questions. The MNIST dataset is a set of 70,000 small images of digits handwritten by high school students and employees of the US Census Bureau. Each image is labeled with the digit it represents. You will use these features to build random forest and deep neural network models to predict the `digit` of an image. First, please place load the data.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4353ca6",
   "metadata": {},
   "source": [
    "#### Load and plot the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b09a4f",
   "metadata": {},
   "source": [
    "Loading MNIST data of 70,000 images may take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98706103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f163103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a95fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the data\n",
    "def plot_digits(instances, images_per_row=5, **options):\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    padded_instances = np.concatenate([instances, np.zeros((n_empty, size * size))], axis=0)\n",
    "\n",
    "    # Reshape the array so it's organized as a grid containing 28×28 images:\n",
    "    image_grid = padded_instances.reshape((n_rows, images_per_row, size, size))\n",
    "    big_image = image_grid.transpose(0, 2, 1, 3).reshape(n_rows * size,\n",
    "                                                         images_per_row * size)\n",
    "    \n",
    "    # Now that we have a big image, we just need to show it:\n",
    "    plt.imshow(big_image, cmap = mpl.cm.binary, **options)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "example_images = X[:25]\n",
    "plot_digits(example_images, images_per_row=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2653d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e92572",
   "metadata": {},
   "source": [
    "<font color='red'><b>About the data used in this assignment: </b></font><br>\n",
    "**The MNIST dataset is actually already split into a training set (the first 60,000 images) and a test set (the last 10,000 images). All the classification models in this lab are trained on `X_train`, `y_train`, and evaluated on `X_test`, `y_test`.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0ab7ee",
   "metadata": {},
   "source": [
    "#### Question 1 (14 points):  \n",
    "Please train a random forest model using <b>random patches</b> in function `answer_one( )`. Random patches is to sample training instances for each decision tree with or without replacement, which can be implemented using bagging ensemble method `BaggingClassifier` over a number of decision trees `DecisionTreeClassifier`; each tree is built upon a subset of training instances. After the random forest is trained, evaluate the performance, including accuracy, micro F1 score, and macro F1 score.\n",
    "\n",
    "**Set `DecisionTreeClassifier()`, `n_estimators=100`, `bootstrap=True` and `random_state=42` in `BaggingClassifier` to formulate random forest through a number of decision trees**\n",
    "\n",
    "**Adjust the option `max_samples=` in `BaggingClassifier` to set the size for each subset of training instances as `1,000`, `2,000` and `3,000`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5a7ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def answer_one():\n",
    "    random_patches = \n",
    "    random_patches.\n",
    "    y_pred = \n",
    "    \n",
    "    #Accuracy: use accuracy_score \n",
    "    accuracy = \n",
    "    \n",
    "    #Micro F1 score: use f1_score with average='micro' \n",
    "    micro_f1 = \n",
    "    \n",
    "    #Micro F1 score: use f1_score with average='macro' \n",
    "    macro_f1 = \n",
    "    \n",
    "    return accuracy, micro_f1, macro_f1\n",
    "\n",
    "#Run your function in the cell to return the results\n",
    "time1_1 = time.time()\n",
    "accuracy_1, microf1_1, macrof1_1 = answer_one()\n",
    "time2_1 = time.time()\n",
    "time_1 = time2_1 - time1_1 \n",
    "\n",
    "#Print your results here\n",
    "print(accuracy_1, microf1_1, macrof1_1, time_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27d7e96",
   "metadata": {},
   "source": [
    "<font color='red'><b>Double click here to answer the questions in this cell: </b></font> <br>\n",
    "Report the performance and time used by three training subset sizes of 1,000, 2,000, and 3,000: <br>\n",
    "<b>`max_samples=1000`</b>: Accuracy is: ( ), Micro f1 score is: ( ), Macro f1 score is: ( ), Time used: ( ) <br>\n",
    "<b>`max_samples=2000`</b>: Accuracy is: ( ), Micro f1 score is: ( ), Macro f1 score is: ( ), Time used: ( ) <br>\n",
    "<b>`max_samples=3000`</b>: Accuracy is: ( ), Micro f1 score is: ( ), Macro f1 score is: ( ), Time used: ( )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28237ee",
   "metadata": {},
   "source": [
    "#### Question 2 (14 points):  \n",
    "Please train a random forest model using <b>random subspaces</b> in function `answer_two( )`. Random subspaces is to sample training features while keeping all training instances for each decision tree, which can be implemented using bagging ensemble method `BaggingClassifier` over a number of decision trees `DecisionTreeClassifier`; each tree is built upon a subset of training features. After the random forest is trained, evaluate the performance, including accuracy, micro F1 score, and macro F1 score.\n",
    "\n",
    "**Set `DecisionTreeClassifier()`, `n_estimators=100` and `random_state=42` in `BaggingClassifier` to formulate random forest through a number of decision trees**\n",
    "\n",
    "**Adjust the option `max_features=` in `BaggingClassifier` to set the size for each subset of features as `10`, `30` and `50`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2312b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_two():\n",
    "    random_subspaces = \n",
    "    random_subspaces.\n",
    "    y_pred = \n",
    "    \n",
    "    accuracy = \n",
    "\n",
    "    micro_f1 = \n",
    "\n",
    "    macro_f1 = \n",
    "    \n",
    "    return accuracy, micro_f1, macro_f1\n",
    "\n",
    "#Run your function in the cell to return the results\n",
    "time1_2 = time.time()\n",
    "accuracy_2, microf1_2, macrof1_2 = answer_two()\n",
    "time2_2 = time.time()\n",
    "time_2 = time2_2 - time1_2 \n",
    "\n",
    "#Print your results here\n",
    "print(accuracy_2, microf1_2, macrof1_2, time_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4750a8ae",
   "metadata": {},
   "source": [
    "<font color='red'><b>Double click here to answer the questions in this cell: </b></font> <br> \n",
    "Report the performance by three feature subset sizes of 10, 30, and 50: <br>\n",
    "<b>`max_features=10`</b>: Accuracy is: ( ), Micro f1 score is: ( ), Macro f1 score is: ( ), Time used: ( ) <br>\n",
    "<b>`max_features=30`</b>: Accuracy is: ( ), Micro f1 score is: ( ), Macro f1 score is: ( ), Time used: ( ) <br>\n",
    "<b>`max_features=50`</b>: Accuracy is: ( ), Micro f1 score is: ( ), Macro f1 score is: ( ), Time used: ( )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9290d7",
   "metadata": {},
   "source": [
    "#### Question 3 (7 points):  \n",
    "<font color='red'><b>Double click here to answer the questions in this cell: </b></font><br>\n",
    "In Question 1, random forest uses random subset of training instances with all features for each decision tree. In Question 2, random forest randomly samples a very small subset of features while keeping all training instances for each decision tree. Both random forests have 100 decision trees. Please <b>compare the best results of these two models</b>: <br> \n",
    "\n",
    "Summarize your observations about their classification performance and time used: ( ) <br>\n",
    "\n",
    "Also briefly explain why one model outperforms the other one: ( )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4535ad",
   "metadata": {},
   "source": [
    "#### Install Tensorflow and Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47630d6",
   "metadata": {},
   "source": [
    "You need to use Keras to build neural networks in the next question. As Keras has been integrated into Tensorflow package, please install Tensorflow (version ≥2.0 is required) as follows if you havn't done so yet:\n",
    "\n",
    "**`python3 -m pip install --upgrade tensorflow`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ffe2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\", \"The version of Tensorflow needs to be ≥2.0\"\n",
    "\n",
    "print(tf.__version__)\n",
    "print(\"The version of Tensorflow you installed is ≥2.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159624d0",
   "metadata": {},
   "source": [
    "#### Preprocess MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d46ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train / 255., X_test / 255.\n",
    "\n",
    "y_train, y_test = y_train.astype(np.uint8), y_test.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a769f5",
   "metadata": {},
   "source": [
    "#### Question 4 (15 points):  \n",
    "Please train a deep neural network (i.e., a multi-layer perceptron) in function `answer_four( )`. After the neural network is trained, evaluate the accuracy.\n",
    "\n",
    "**Set dropout rate in `keras.layers.Dropout()` as `0.3`, `0.5` and `0.7` respectively to compare the different performance**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19561043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "def answer_four():\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Input(shape=(784,)),\n",
    "                                                     #Dense hidden layer, 300 neurons, ReLU\n",
    "                                                     #Dropout layer to address ovefitting\n",
    "                                                     #Dense hidden layer, 100 neurons, ReLU \n",
    "                                                     #Dropout layer to address overfitting\n",
    "                                                     #Dense output layer, 10 neurons, softmax\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "                                                     #Loss function \n",
    "                                                     #Optimization algorithm: adam\n",
    "                                                     #Batch size for gradient descent: 64\n",
    "                                                     #Evaluatuion metrics: accuracy \n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=30,\n",
    "             validation_data=(X_test, y_test))\n",
    "    \n",
    "    loss, accuracy_4 = model.evaluate(X_test, y_test)   \n",
    "    \n",
    "    return accuracy_4\n",
    "\n",
    "#Run your function in the cell to return the results\n",
    "accuracy_4 = answer_four()\n",
    "\n",
    "#Print your results here\n",
    "print(\"\\nThe test accuracy is: \", accuracy_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859f25dc",
   "metadata": {},
   "source": [
    "<font color='red'><b>Double click here to answer the questions in this cell: </b></font> <br>\n",
    "Report the performance by three dropout rate of 0.3, 0.5, and 0.7: <br>\n",
    "<b>`keras.layers.Dropout(0.3)`</b>: Test accuracy is: ( ) <br>\n",
    "<b>`keras.layers.Dropout(0.5)`</b>: Test cccuracy is: ( ) <br>\n",
    "<b>`keras.layers.Dropout(0.7)`</b>: Test accuracy is: ( ) \n",
    "\n",
    "Based on the test accuracy, and the difference between training accuracy and validation accuracy printed out in the training log, please summarize the impact of dropout on the model performance: ( )\n",
    "\n",
    "Based on the best performance of neural networks and the best performance of random forest, which model outperforms the other one: ( )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
